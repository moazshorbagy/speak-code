{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deepspeech-timit.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "0ZBrmPYtVB8h",
        "qSGrGgUfVe23",
        "dLvX4371Whe9"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ZBrmPYtVB8h",
        "colab_type": "text"
      },
      "source": [
        "## **Dataset and Model Files**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnYXLLtGU3Qi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.mkdir('Seq2Seq')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vtIOZsVVBPZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.upload() #upload kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufMTI-FSVBZF",
        "colab_type": "text"
      },
      "source": [
        "Mount google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAp9p8JfVIQI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7IU-A3V9VK-f",
        "colab_type": "text"
      },
      "source": [
        "### Download and process TIMIT dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7bokbguVKP8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -q kaggle\n",
        "!mkdir -p ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "!chmod 600 /root/.kaggle/kaggle.json\n",
        "!kaggle datasets download mfekadu/darpa-timit-acousticphonetic-continuous-speech\n",
        "!unzip -q darpa-timit-acousticphonetic-continuous-speech.zip -d Timit_dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2I3HQ7e7VM7J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import shutil\n",
        "import os\n",
        "os.mkdir('Seq2Seq/TIMIT')\n",
        "shutil.move('Timit_dataset/data/TRAIN','Seq2Seq/TIMIT')\n",
        "shutil.move('Timit_dataset/data/TEST','Seq2Seq/TIMIT')\n",
        "shutil.rmtree('Timit_dataset', ignore_errors=True)\n",
        "os.remove('darpa-timit-acousticphonetic-continuous-speech.zip')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tYM_AWewVOcW",
        "colab_type": "text"
      },
      "source": [
        "Move to deepspeech directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VO4OFYyVPoI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir('Seq2Seq')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1Yx8ZhIVQ_k",
        "colab_type": "text"
      },
      "source": [
        "Upload model files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkSrp5HMVRGI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1DM4NCbGVWYZ",
        "colab_type": "text"
      },
      "source": [
        "Prepare TIMIT dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6Ue6xgIVVrx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python3 prepare_timit.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSGrGgUfVe23",
        "colab_type": "text"
      },
      "source": [
        "## **Model Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhfNvEFaVe8f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from model import create_model, create_optimizer, create_model_checkpoint_cb, create_lr_scheduler_cb\n",
        "from visualization import plot_accuracy, plot_loss\n",
        "from BeamSearch import ctcBeamSearch\n",
        "from dataset import create_dataset\n",
        "from generator import generator\n",
        "from text import decode\n",
        "import constants as c\n",
        "\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras import backend as k\n",
        "from tensorflow.keras.models import Model\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idBUIQu-Vs81",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = create_dataset()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SgIzevGAVs_b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = create_model()\n",
        "\n",
        "model.summary()\n",
        "\n",
        "plot_model(model, to_file='rnn.png')\n",
        "\n",
        "optimizer = create_optimizer()\n",
        "\n",
        "loss = {'ctc': lambda y_true, y_pred: y_pred}\n",
        "\n",
        "model.compile(loss=loss, optimizer=optimizer, metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omxz6cHOVtCf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit(\n",
        "    generator(X_train, y_train, c.batch_size),\n",
        "    steps_per_epoch=int(np.ceil(X_train.shape[0]/c.batch_size)),\n",
        "    epochs=50,\n",
        "    validation_data=generator(X_test, y_test, c.batch_size),\n",
        "    validation_steps=int(np.ceil(X_test.shape[0]/c.batch_size)),\n",
        "    callbacks=[create_model_checkpoint_cb(), create_lr_scheduler_cb()],\n",
        "    initial_epoch=20\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFQvehGIVtE_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_accuracy(history)\n",
        "plot_loss(history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjWZ6vBNWRi2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights(c.checkpoint_filepath)\n",
        "model.save_weights(\"model.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLvX4371Whe9",
        "colab_type": "text"
      },
      "source": [
        "## **Model Prediction**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1caxjKS-V3ij",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sub_model = Model(inputs=model.get_layer('masking_layer').input, outputs=model.get_layer('output_layer').output)\n",
        "\n",
        "for i in range(10):\n",
        "    data = X_test[i]\n",
        "    d = np.array([data])\n",
        "    \n",
        "    prediction=sub_model.predict(d)\n",
        "    output = k.get_value(prediction)        \n",
        "    path = ctcBeamSearch(output[0], ''.join(c.alphabet), None)\n",
        "\n",
        "    print('true:', decode(y_test[i]))\n",
        "    print('pred:', path)\n",
        "    print()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}